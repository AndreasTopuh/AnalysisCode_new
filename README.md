# ğŸ“Š LAPORAN LENGKAP: Feature Selection dan Model Training untuk Deteksi URL Phishing

---

## ğŸ“‹ DAFTAR ISI
1. [Ringkasan Eksekutif](#1-ringkasan-eksekutif)
2. [Pendahuluan & Latar Belakang](#2-pendahuluan--latar-belakang)
3. [Dataset yang Digunakan](#3-dataset-yang-digunakan)
4. [Metodologi Penelitian](#4-metodologi-penelitian)
5. [Penjelasan Kode Secara Detail](#5-penjelasan-kode-secara-detail)
6. [Metode Feature Selection](#6-metode-feature-selection)
7. [Model Machine Learning](#7-model-machine-learning)
8. [Hyperparameter dan Alasannya](#8-hyperparameter-dan-alasannya)
9. [Perbandingan dengan Jurnal Prasad](#9-perbandingan-dengan-jurnal-prasad)
10. [Hasil Eksperimen](#10-hasil-eksperimen)
11. [Analisis dan Interpretasi Hasil](#11-analisis-dan-interpretasi-hasil)
12. [Kesimpulan dan Rekomendasi](#12-kesimpulan-dan-rekomendasi)

---

## 1. RINGKASAN EKSEKUTIF

### ğŸ¯ Tujuan Penelitian
Penelitian ini bertujuan untuk **mendeteksi URL phishing** menggunakan machine learning dengan mengevaluasi:
- **4 metode Feature Selection**: Boruta, RFE, Correlation, dan ContrastFS
- **3 model klasifikasi**: Random Forest, XGBoost (GradientBoosting), dan SVM
- **Perbandingan**: Top 10 Features vs All Features (57 fitur)

### ğŸ“ˆ Hasil Utama
| Metrik | Best Performer | Nilai |
|--------|----------------|-------|
| **Accuracy Tertinggi** | All Features + Random Forest | 99.92% |
| **Top 10 Features Terbaik** | RFE + XGBoost | 99.87% |
| **Training Tercepat** | Correlation + Random Forest | 18.03 detik |
| **Efisiensi Terbaik** | RFE (akurasi tinggi + waktu cepat) | 99.87% dalam 33.98 detik |

---

## 2. PENDAHULUAN & LATAR BELAKANG

### 2.1 Apa itu URL Phishing?
**Phishing** adalah serangan cyber di mana penyerang membuat website palsu yang meniru website asli (bank, e-commerce, sosial media) untuk mencuri informasi sensitif pengguna seperti:
- Username dan password
- Nomor kartu kredit
- Data pribadi lainnya

### 2.2 Mengapa Perlu Deteksi Otomatis?
- **Volume tinggi**: Ribuan URL phishing baru muncul setiap hari
- **Evolusi cepat**: Penyerang terus mengembangkan teknik baru
- **Manusia tidak cukup**: Manual review tidak skalabel
- **Machine Learning** memberikan solusi otomatis, cepat, dan akurat

### 2.3 Peran Feature Selection
Dengan **63 fitur original**, memilih fitur yang paling relevan sangat penting karena:
1. **Mengurangi overfitting** - model lebih general
2. **Mempercepat training** - lebih sedikit fitur = lebih cepat
3. **Meningkatkan interpretabilitas** - memahami fitur mana yang penting
4. **Mengurangi noise** - menghilangkan fitur yang tidak relevan

---

## 3. DATASET YANG DIGUNAKAN

### 3.1 Informasi Dataset
| Atribut | Nilai |
|---------|-------|
| **Nama Dataset** | PhiUSIIL Phishing URL Dataset |
| **File** | `PhiUSIIL_Phishing_URL_63_Features.csv` |
| **Jumlah Sampel** | 235,795 URL |
| **Jumlah Fitur Original** | 63 fitur |
| **Jumlah Fitur Numerik** | 57 fitur (setelah drop kolom non-numerik) |
| **Target Variable** | `label` (0 = Legitimate, 1 = Phishing) |

### 3.2 Kolom yang Di-drop (Non-Numerik)
Kolom berikut tidak digunakan dalam training karena bukan fitur numerik:
```
- FILENAME: Nama file
- URL: String URL lengkap
- Domain: Nama domain
- TLD: Top Level Domain (.com, .org, dll)
- Title: Judul halaman web
```

### 3.3 Distribusi Kelas
Dataset ini relatif **seimbang (balanced)**, yang penting untuk evaluasi yang fair:
- **Phishing (1)**: ~50% dari dataset
- **Legitimate (0)**: ~50% dari dataset

### 3.4 Kategori Fitur dalam Dataset
Fitur-fitur dalam dataset dapat dikategorikan sebagai berikut:

#### A. URL-based Features (Fitur berbasis URL)
| Fitur | Deskripsi |
|-------|-----------|
| `URLLength` | Panjang URL (phishing URL cenderung lebih panjang) |
| `URLCharProb` | Probabilitas karakter dalam URL |
| `LetterRatioInURL` | Rasio huruf dalam URL |
| `SpacialCharRatioInURL` | Rasio karakter spesial dalam URL |
| `URL_Profanity_Prob` | Probabilitas konten tidak pantas dalam URL |

#### B. Content-based Features (Fitur berbasis konten halaman)
| Fitur | Deskripsi |
|-------|-----------|
| `LineOfCode` | Jumlah baris kode HTML |
| `LargestLineLength` | Panjang baris terpanjang dalam kode |
| `NoOfJS` | Jumlah file JavaScript yang dimuat |
| `NoOfCSS` | Jumlah file CSS yang dimuat |
| `NoOfImage` | Jumlah gambar pada halaman |
| `NoOfExternalRef` | Jumlah referensi eksternal |
| `NoOfSelfRef` | Jumlah referensi ke diri sendiri |

#### C. Metadata Features (Fitur metadata halaman)
| Fitur | Deskripsi |
|-------|-----------|
| `HasDescription` | Apakah memiliki meta description (0/1) |
| `HasSocialNet` | Apakah ada link ke sosial media (0/1) |
| `HasCopyrightInfo` | Apakah ada informasi copyright (0/1) |
| `HasFavicon` | Apakah ada favicon (0/1) |
| `HasSubmitButton` | Apakah ada tombol submit (0/1) |
| `HasHiddenFields` | Apakah ada field tersembunyi (0/1) |
| `IsResponsive` | Apakah halaman responsive (0/1) |

#### D. Similarity Features (Fitur kesamaan)
| Fitur | Deskripsi |
|-------|-----------|
| `DomainTitleMatchScore` | Skor kecocokan domain dengan title |
| `URLTitleMatchScore` | Skor kecocokan URL dengan title |

---

## 4. METODOLOGI PENELITIAN

### 4.1 Alur Penelitian (Pipeline)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PIPELINE PENELITIAN                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  1. LOAD     â”‚â”€â”€â”€â–¶â”‚  2. PREPROCESSING â”‚â”€â”€â”€â–¶â”‚  3. FEATURE        â”‚    â”‚
â”‚  â”‚  DATASET     â”‚    â”‚  - Drop non-numerikâ”‚   â”‚  SELECTION         â”‚    â”‚
â”‚  â”‚  (235,795)   â”‚    â”‚  - Handle missing  â”‚   â”‚  - Boruta          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - Standardization â”‚   â”‚  - RFE             â”‚    â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - Correlation     â”‚    â”‚
â”‚                                               â”‚  - ContrastFS      â”‚    â”‚
â”‚                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚               â”‚
â”‚                                                         â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  6. HASIL    â”‚â—€â”€â”€â”€â”‚  5. EVALUASI      â”‚â—€â”€â”€â”€â”‚  4. MODEL          â”‚   â”‚
â”‚  â”‚  & ANALISIS  â”‚    â”‚  5-Fold CV        â”‚    â”‚  TRAINING          â”‚   â”‚
â”‚  â”‚              â”‚    â”‚  - Accuracy       â”‚    â”‚  - Random Forest   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - Precision      â”‚    â”‚  - XGBoost         â”‚   â”‚
â”‚                      â”‚  - Recall         â”‚    â”‚  - SVM             â”‚   â”‚
â”‚                      â”‚  - F1 Score       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â”‚  - Training Time  â”‚                              â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Validasi: 5-Fold Stratified Cross Validation

#### Apa itu 5-Fold Stratified Cross Validation?

```
Dataset Total (235,795 sampel)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STRATIFIED K-FOLD (K=5)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Fold 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TRAIN (80%) â”‚ [â–ˆâ–ˆâ–ˆâ–ˆ] TEST (20%) â”‚
â”‚          188,636 sampel                     â”‚ 47,159 sampel     â”‚
â”‚                                                                  â”‚
â”‚  Fold 2: [â–ˆâ–ˆâ–ˆâ–ˆ] TEST â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TRAIN (80%)       â”‚
â”‚          47,159      â”‚ 188,636 sampel                           â”‚
â”‚                                                                  â”‚
â”‚  Fold 3: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TRAIN â”‚ [â–ˆâ–ˆâ–ˆâ–ˆ] TEST â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TRAIN      â”‚
â”‚                                                                  â”‚
â”‚  Fold 4: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TRAIN â”‚ [â–ˆâ–ˆâ–ˆâ–ˆ] TEST â”‚ [â–ˆâ–ˆâ–ˆâ–ˆ] TRAIN      â”‚
â”‚                                                                  â”‚
â”‚  Fold 5: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TRAIN (80%) â”‚ [â–ˆâ–ˆâ–ˆâ–ˆ] TEST       â”‚
â”‚                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  "STRATIFIED" = Proporsi kelas (Phishing/Legitimate) SAMA       â”‚
â”‚                 di setiap fold untuk evaluasi yang FAIR         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Final Score = Mean(Fold1, Fold2, Fold3, Fold4, Fold5) Â± Std
```

#### Mengapa Menggunakan 5-Fold CV?
1. **Mengurangi bias**: Setiap data digunakan untuk testing tepat 1x
2. **Evaluasi robust**: Hasil lebih dapat diandalkan daripada single split
3. **Stratified**: Menjaga proporsi kelas di setiap fold
4. **Standard industri**: Banyak digunakan dalam penelitian ML

---

## 5. PENJELASAN KODE SECARA DETAIL

### 5.1 Cell 1 - Import Libraries

```python
import pandas as pd          # Manipulasi data (DataFrame)
import numpy as np           # Operasi numerik
import time                  # Mengukur waktu training
import warnings
warnings.filterwarnings('ignore')  # Sembunyikan warning

# Sklearn - Library machine learning
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer

# Boruta - Feature Selection
from boruta import BorutaPy
```

**Penjelasan setiap import:**

| Library | Fungsi |
|---------|--------|
| `pandas` | Membaca CSV, manipulasi DataFrame |
| `numpy` | Operasi array dan matematika |
| `time` | Mengukur durasi training |
| `StratifiedKFold` | Membagi data dengan proporsi kelas sama |
| `cross_validate` | Menjalankan cross validation |
| `StandardScaler` | Normalisasi fitur (mean=0, std=1) |
| `RandomForestClassifier` | Model ensemble berbasis decision tree |
| `GradientBoostingClassifier` | Model boosting (alternatif XGBoost) |
| `SVC` | Support Vector Machine untuk klasifikasi |

---

### 5.2 Cell 2 - Load Dataset

```python
# Load dataset
df = pd.read_csv('PhiUSIIL_Phishing_URL_63_Features.csv')

print(f"Dataset shape: {df.shape}")
print(f"\nColumns: {df.columns.tolist()}")
print(f"\nLabel distribution:\n{df['label'].value_counts()}")
```

**Penjelasan:**
- `pd.read_csv()`: Membaca file CSV ke dalam DataFrame
- `df.shape`: Menampilkan (jumlah_baris, jumlah_kolom)
- `df.columns.tolist()`: Daftar semua nama kolom
- `df['label'].value_counts()`: Menghitung distribusi kelas target

---

### 5.3 Cell 3 - Data Preprocessing

```python
# Kolom non-numerik yang harus di-drop
non_numeric_cols = ['FILENAME', 'URL', 'Domain', 'TLD', 'Title']

# Drop kolom non-numerik
df_numeric = df.drop(columns=non_numeric_cols, errors='ignore')

# Pisahkan fitur dan target
X = df_numeric.drop(columns=['label'])  # Semua kolom kecuali label
y = df_numeric['label']                  # Hanya kolom label

# Handle missing values dengan median
X = X.fillna(X.median())

# Pastikan semua kolom numerik
X = X.apply(pd.to_numeric, errors='coerce')
X = X.fillna(X.median())
```

**Penjelasan Step-by-Step:**

| Step | Kode | Alasan |
|------|------|--------|
| 1 | Drop non-numerik | Model ML hanya bisa proses angka |
| 2 | Pisah X dan y | X = fitur input, y = target output |
| 3 | Fill missing dengan median | Median robust terhadap outlier |
| 4 | Konversi ke numerik | Memastikan tipe data konsisten |

**Mengapa Median, bukan Mean?**
- **Median** tidak terpengaruh oleh outlier
- Contoh: [1, 2, 3, 4, 100] â†’ Mean=22, Median=3
- Median lebih representatif untuk data dengan outlier

---

### 5.4 Cell 4 - Pre-defined Top 10 Features

```python
# Boruta Top 10 Features
boruta_top10 = [
    'LineOfCode',        # Jumlah baris kode HTML
    'NoOfExternalRef',   # Jumlah referensi eksternal
    'NoOfSelfRef',       # Jumlah referensi internal
    'NoOfJS',            # Jumlah file JavaScript
    'HasDescription',    # Ada meta description?
    'NoOfImage',         # Jumlah gambar
    'HasSocialNet',      # Ada link sosial media?
    'NoOfCSS',           # Jumlah file CSS
    'HasCopyrightInfo',  # Ada info copyright?
    'LargestLineLength'  # Panjang baris terpanjang
]

# RFE Top 10 Features
rfe_top10 = [
    'LineOfCode',             # Jumlah baris kode HTML
    'LargestLineLength',      # Panjang baris terpanjang
    'NoOfExternalRef',        # Jumlah referensi eksternal
    'URLCharProb',            # Probabilitas karakter URL
    'LetterRatioInURL',       # Rasio huruf dalam URL
    'SpacialCharRatioInURL',  # Rasio karakter spesial
    'NoOfCSS',                # Jumlah file CSS
    'URL_Profanity_Prob',     # Probabilitas konten tidak pantas
    'URLLength',              # Panjang URL
    'NoOfJS'                  # Jumlah file JavaScript
]

# Correlation Top 10 Features
correlation_top10 = [
    'HasSocialNet',           # Ada link sosial media?
    'HasCopyrightInfo',       # Ada info copyright?
    'HasDescription',         # Ada meta description?
    'SpacialCharRatioInURL',  # Rasio karakter spesial
    'HasHiddenFields',        # Ada field tersembunyi?
    'HasFavicon',             # Ada favicon?
    'DomainTitleMatchScore',  # Kecocokan domain-title
    'HasSubmitButton',        # Ada tombol submit?
    'IsResponsive',           # Halaman responsive?
    'URLTitleMatchScore'      # Kecocokan URL-title
]

# ContrastFS Top 10 Features (sama dengan Correlation)
contrast_top10 = [
    'HasSocialNet',
    'HasCopyrightInfo',
    'HasDescription',
    'SpacialCharRatioInURL',
    'HasHiddenFields',
    'HasFavicon',
    'HasSubmitButton',
    'DomainTitleMatchScore',
    'IsResponsive',
    'URLTitleMatchScore'
]
```

**Insight Menarik:**
- **Boruta & RFE** fokus pada fitur **teknis** (LineOfCode, NoOfJS, dll)
- **Correlation & ContrastFS** fokus pada fitur **metadata** (HasSocialNet, HasCopyrightInfo, dll)
- Ini menunjukkan bahwa ada **dua pendekatan** untuk mendeteksi phishing

---

### 5.5 Cell 5 - Training Function dengan 5-Fold CV

```python
def train_and_evaluate_cv(X, y, model, model_name, n_splits=5):
    """
    Train model dengan 5-Fold Stratified Cross Validation
    """
    # Setup 5-Fold Stratified Cross Validation
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    # Print distribusi kelas di setiap fold
    print("DISTRIBUSI KELAS DI SETIAP FOLD")
    for fold_num, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):
        y_train = y.iloc[train_idx]
        y_test = y.iloc[test_idx]
        print(f"FOLD {fold_num}")
        print(f"  TRAINING: {len(y_train)} samples")
        print(f"  TESTING: {len(y_test)} samples")

    # Define scorers untuk multiple metrics
    scorers = {
        'accuracy': make_scorer(accuracy_score),
        'precision': make_scorer(precision_score, average='binary'),
        'recall': make_scorer(recall_score, average='binary'),
        'f1': make_scorer(f1_score, average='binary')
    }
    
    # Start timer
    start_time = time.time()
    
    # Perform cross validation
    cv_results = cross_validate(
        model, X, y, 
        cv=skf, 
        scoring=scorers,
        return_train_score=False,
        n_jobs=-1  # Gunakan semua CPU cores
    )
    
    # End timer
    training_time = time.time() - start_time
    
    # Calculate mean dan std untuk setiap metric
    metrics = {
        'accuracy': cv_results['test_accuracy'].mean(),
        'accuracy_std': cv_results['test_accuracy'].std(),
        'precision': cv_results['test_precision'].mean(),
        'precision_std': cv_results['test_precision'].std(),
        'recall': cv_results['test_recall'].mean(),
        'recall_std': cv_results['test_recall'].std(),
        'f1': cv_results['test_f1'].mean(),
        'f1_std': cv_results['test_f1'].std(),
        'training_time': training_time
    }
    
    return metrics
```

**Penjelasan Parameter:**

| Parameter | Nilai | Penjelasan |
|-----------|-------|------------|
| `n_splits=5` | 5 | Jumlah fold untuk cross validation |
| `shuffle=True` | True | Acak data sebelum split |
| `random_state=42` | 42 | Seed untuk reproducibility |
| `n_jobs=-1` | -1 | Gunakan semua CPU cores (paralel) |
| `average='binary'` | binary | Untuk klasifikasi binary (2 kelas) |

---

### 5.6 Cell 6 - Model Definitions

```python
def get_models(n_features):
    """
    Get models dengan max_depth yang disesuaikan jumlah fitur:
    - Untuk 10 features: max_depth = 10
    - Untuk 57 features (all): max_depth = 20
    """
    # Tentukan max_depth berdasarkan jumlah fitur
    if n_features <= 10:
        max_depth = 10  # Untuk top 10 features
    else:
        max_depth = 20  # Untuk all features (57)
    
    return {
        # Random Forest
        'Random Forest': RandomForestClassifier(
            n_estimators=100,      # Jumlah decision tree
            max_depth=max_depth,   # Kedalaman maksimum tree
            random_state=42,       # Untuk reproducibility
            n_jobs=-1              # Paralel processing
        ),
        
        # XGBoost (GradientBoosting sebagai alternatif)
        'XGBoost': GradientBoostingClassifier(
            n_estimators=100,              # Jumlah boosting stages
            max_depth=min(max_depth, 10),  # Max depth (lebih shallow)
            random_state=42
        ),
        
        # SVM dengan RBF kernel
        'SVM': SVC(
            kernel='rbf',      # Radial Basis Function kernel
            C=1.0,             # Regularization parameter
            gamma='scale',     # Kernel coefficient
            random_state=42
        )
    }
```

---

### 5.7 Cell 7 - Main Training Loop

```python
for fs_name, features in feature_sets.items():
    n_features = len(features)
    print(f"Feature Set: {fs_name} ({n_features} features)")
    
    # Inisialisasi hasil untuk setiap feature set
    results['Accuracy'][fs_name] = {}
    results['Precision'][fs_name] = {}
    results['Recall'][fs_name] = {}
    results['F1'][fs_name] = {}
    results['Training Time'][fs_name] = {}
    
    # Select features
    X_fs = X[features]
    
    # PENTING: StandardScaler untuk normalisasi
    scaler_fs = StandardScaler()
    X_fs_scaled = scaler_fs.fit_transform(X_fs)
    
    # Get models dengan max_depth yang sesuai
    models = get_models(n_features)
    
    # Training setiap model
    for model_name, model in models.items():
        print(f"  Training {model_name}...")
        
        # Train dan evaluate dengan 5-Fold CV
        metrics = train_and_evaluate_cv(
            X_fs_scaled, y, 
            model, model_name,
            n_splits=5
        )
        
        # Simpan hasil
        results['Accuracy'][fs_name][model_name] = metrics['accuracy']
        results['Precision'][fs_name][model_name] = metrics['precision']
        results['Recall'][fs_name][model_name] = metrics['recall']
        results['F1'][fs_name][model_name] = metrics['f1']
        results['Training Time'][fs_name][model_name] = metrics['training_time']
```

**Mengapa StandardScaler?**

```
SEBELUM SCALING:          SETELAH SCALING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ URLLength: 0-2000â”‚       â”‚ URLLength: -2 to +2â”‚
â”‚ NoOfJS: 0-10    â”‚  â”€â”€â”€â–¶  â”‚ NoOfJS: -2 to +2   â”‚
â”‚ LineOfCode: 0-50000â”‚    â”‚ LineOfCode: -2 to +2â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      SKALA BEDA                SKALA SAMA

Rumus: X_scaled = (X - mean) / std
- Mean = 0
- Std = 1
```

**Mengapa penting untuk SVM?**
- SVM sangat sensitif terhadap skala fitur
- Fitur dengan nilai besar akan mendominasi
- Scaling membuat semua fitur sama pentingnya

---

## 6. METODE FEATURE SELECTION

### 6.1 Boruta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CARA KERJA BORUTA                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. BUAT SHADOW FEATURES (kopian acak dari fitur asli)         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚ Original: [F1, F2, F3, F4, F5]                      â”‚    â”‚
â”‚     â”‚ Shadow:   [S1, S2, S3, S4, S5] â† nilai diacak       â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  2. TRAIN RANDOM FOREST dengan semua fitur (original + shadow) â”‚
â”‚                                                                 â”‚
â”‚  3. HITUNG IMPORTANCE setiap fitur                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚ F1: 0.15  |  F2: 0.08  |  F3: 0.22  |  F4: 0.05     â”‚    â”‚
â”‚     â”‚ S1: 0.02  |  S2: 0.03  |  S3: 0.01  |  S4: 0.02     â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  4. BANDINGKAN: Fitur dengan importance > max(shadow) = PENTING â”‚
â”‚     - Max shadow importance = 0.03                              â”‚
â”‚     - F1(0.15) > 0.03 âœ… | F2(0.08) > 0.03 âœ…                  â”‚
â”‚     - F3(0.22) > 0.03 âœ… | F4(0.05) > 0.03 âœ…                  â”‚
â”‚                                                                 â”‚
â”‚  5. ULANGI beberapa iterasi untuk hasil stabil                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Kelebihan Boruta:**
- âœ… Wrapper method - mempertimbangkan interaksi antar fitur
- âœ… Statistik rigorous - menggunakan statistical test
- âœ… Menghindari false positives - shadow features sebagai control

**Fitur yang Dipilih Boruta:**
1. LineOfCode, 2. NoOfExternalRef, 3. NoOfSelfRef, 4. NoOfJS
5. HasDescription, 6. NoOfImage, 7. HasSocialNet, 8. NoOfCSS
9. HasCopyrightInfo, 10. LargestLineLength

---

### 6.2 RFE (Recursive Feature Elimination)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CARA KERJA RFE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  MULAI: 57 fitur                                               â”‚
â”‚                                                                 â”‚
â”‚  Iterasi 1: Train model â†’ Hapus fitur paling tidak penting     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ [F1, F2, F3, ..., F57] â†’ Hapus F42 (paling tidak penting)â”‚   â”‚
â”‚  â”‚ Sisa: 56 fitur                                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  Iterasi 2: Train model â†’ Hapus fitur paling tidak penting     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ [F1, F2, F3, ..., F56] â†’ Hapus F31 (paling tidak penting)â”‚   â”‚
â”‚  â”‚ Sisa: 55 fitur                                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  ... (ulangi sampai tersisa 10 fitur)                          â”‚
â”‚                                                                 â”‚
â”‚  Iterasi 47: Tersisa 10 fitur terbaik!                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ [LineOfCode, LargestLineLength, NoOfExternalRef, ...]    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Kelebihan RFE:**
- âœ… Systematic - eliminasi bertahap dari yang terburuk
- âœ… Mempertimbangkan model spesifik
- âœ… Ranking fitur yang jelas

**Fitur yang Dipilih RFE:**
1. LineOfCode, 2. LargestLineLength, 3. NoOfExternalRef, 4. URLCharProb
5. LetterRatioInURL, 6. SpacialCharRatioInURL, 7. NoOfCSS
8. URL_Profanity_Prob, 9. URLLength, 10. NoOfJS

---

### 6.3 Correlation-based Selection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CARA KERJA CORRELATION                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. HITUNG KORELASI setiap fitur dengan target (label)         â”‚
â”‚                                                                 â”‚
â”‚     Correlation Matrix dengan Target:                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚ HasSocialNet      â†â”€â”€â”€â”€â”€â”€â†’ label  â”‚ r = 0.45 â˜…â˜…â˜…    â”‚   â”‚
â”‚     â”‚ HasCopyrightInfo  â†â”€â”€â”€â”€â”€â”€â†’ label  â”‚ r = 0.42 â˜…â˜…â˜…    â”‚   â”‚
â”‚     â”‚ URLLength         â†â”€â”€â”€â”€â”€â”€â†’ label  â”‚ r = 0.15 â˜…      â”‚   â”‚
â”‚     â”‚ NoOfJS            â†â”€â”€â”€â”€â”€â”€â†’ label  â”‚ r = 0.08        â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  2. RANKING berdasarkan |korelasi| (nilai absolut)             â”‚
â”‚                                                                 â”‚
â”‚  3. PILIH TOP 10 dengan korelasi tertinggi                     â”‚
â”‚                                                                 â”‚
â”‚  CATATAN: Tidak mempertimbangkan interaksi antar fitur!        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Kelebihan:**
- âœ… Cepat dan sederhana
- âœ… Mudah diinterpretasi

**Kekurangan:**
- âŒ Tidak mempertimbangkan interaksi antar fitur
- âŒ Bisa memilih fitur redundan

---

### 6.4 ContrastFS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CARA KERJA CONTRASTFS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. BAGI data menjadi dua kelompok berdasarkan target          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚ Group 1: Phishing (label = 1)                       â”‚    â”‚
â”‚     â”‚ Group 2: Legitimate (label = 0)                     â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  2. HITUNG distribusi fitur di setiap grup                     â”‚
â”‚                                                                 â”‚
â”‚  3. UKUR KONTRAS: Fitur yang paling BERBEDA antar grup         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚ HasSocialNet:                                        â”‚    â”‚
â”‚     â”‚   - Phishing: 10% memiliki link sosmed               â”‚    â”‚
â”‚     â”‚   - Legitimate: 85% memiliki link sosmed             â”‚    â”‚
â”‚     â”‚   â†’ KONTRAS TINGGI! â˜…â˜…â˜… (Selected)                   â”‚    â”‚
â”‚     â”‚                                                       â”‚    â”‚
â”‚     â”‚ URLLength:                                            â”‚    â”‚
â”‚     â”‚   - Phishing: avg 50 chars                           â”‚    â”‚
â”‚     â”‚   - Legitimate: avg 45 chars                         â”‚    â”‚
â”‚     â”‚   â†’ KONTRAS RENDAH (Not selected)                    â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  4. PILIH fitur dengan kontras tertinggi                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Kelebihan:**
- âœ… Fokus pada fitur yang benar-benar membedakan kelas
- âœ… Intuitif dan interpretable

---

### 6.5 Perbandingan Hasil Feature Selection

| Rank | Boruta | RFE | Correlation | ContrastFS |
|------|--------|-----|-------------|------------|
| 1 | LineOfCode | LineOfCode | HasSocialNet | HasSocialNet |
| 2 | NoOfExternalRef | LargestLineLength | HasCopyrightInfo | HasCopyrightInfo |
| 3 | NoOfSelfRef | NoOfExternalRef | HasDescription | HasDescription |
| 4 | NoOfJS | URLCharProb | SpacialCharRatioInURL | SpacialCharRatioInURL |
| 5 | HasDescription | LetterRatioInURL | HasHiddenFields | HasHiddenFields |
| 6 | NoOfImage | SpacialCharRatioInURL | HasFavicon | HasFavicon |
| 7 | HasSocialNet | NoOfCSS | DomainTitleMatchScore | HasSubmitButton |
| 8 | NoOfCSS | URL_Profanity_Prob | HasSubmitButton | DomainTitleMatchScore |
| 9 | HasCopyrightInfo | URLLength | IsResponsive | IsResponsive |
| 10 | LargestLineLength | NoOfJS | URLTitleMatchScore | URLTitleMatchScore |

**Insight:**
- **Boruta & RFE**: Memilih fitur teknis (content-based)
- **Correlation & ContrastFS**: Memilih fitur metadata (hampir identik!)

---

## 7. MODEL MACHINE LEARNING

### 7.1 Random Forest

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RANDOM FOREST                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  KONSEP: "Wisdom of the Crowd" - banyak kepala lebih baik!     â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Tree 1  â”‚  â”‚ Tree 2  â”‚  â”‚ Tree 3  â”‚  ...  â”‚Tree 100 â”‚       â”‚
â”‚  â”‚   ğŸŒ³    â”‚  â”‚   ğŸŒ³    â”‚  â”‚   ğŸŒ³    â”‚       â”‚   ğŸŒ³    â”‚       â”‚
â”‚  â”‚ Pred: 1 â”‚  â”‚ Pred: 0 â”‚  â”‚ Pred: 1 â”‚       â”‚ Pred: 1 â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚            â”‚            â”‚                  â”‚            â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                   â”‚  VOTING       â”‚                             â”‚
â”‚                   â”‚  75 Ã— "1"     â”‚                             â”‚
â”‚                   â”‚  25 Ã— "0"     â”‚                             â”‚
â”‚                   â”‚  â†’ Pred = 1 â˜… â”‚                             â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                 â”‚
â”‚  KEUNGGULAN:                                                    â”‚
â”‚  âœ… Robust terhadap overfitting                                â”‚
â”‚  âœ… Handle data besar dengan baik                              â”‚
â”‚  âœ… Tidak perlu scaling (tree-based)                           â”‚
â”‚  âœ… Feature importance built-in                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 7.2 XGBoost (Gradient Boosting)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  XGBOOST / GRADIENT BOOSTING                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  KONSEP: "Learn from mistakes" - perbaiki error secara iteratifâ”‚
â”‚                                                                 â”‚
â”‚  Iterasi 1:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚ Tree 1  â”‚ â†’ Prediksi â†’ Error = [0.3, -0.2, 0.5, ...]        â”‚
â”‚  â”‚   ğŸŒ³    â”‚                                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  Iterasi 2:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚ Tree 2  â”‚ â†’ Fokus pada ERROR dari Tree 1!                   â”‚
â”‚  â”‚   ğŸŒ³    â”‚ â†’ Perbaiki kesalahan                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  ... (100 iterasi)                                              â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  Final Prediction = Tree1 + Tree2 + ... + Tree100              â”‚
â”‚                                                                 â”‚
â”‚  KEUNGGULAN:                                                    â”‚
â”‚  âœ… Akurasi sangat tinggi                                      â”‚
â”‚  âœ… Handle missing values                                      â”‚
â”‚  âœ… Regularization built-in                                    â”‚
â”‚  âŒ Lebih lambat dari Random Forest                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Catatan:** 
Dalam notebook ini, kami menggunakan `GradientBoostingClassifier` dari scikit-learn sebagai alternatif XGBoost karena XGBoost memerlukan OpenMP runtime yang tidak terinstall.

---

### 7.3 SVM (Support Vector Machine)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SUPPORT VECTOR MACHINE (SVM)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  KONSEP: Cari "hyperplane" yang memisahkan kelas dengan margin â”‚
â”‚          terbesar                                               â”‚
â”‚                                                                 â”‚
â”‚        Feature 2                                                â”‚
â”‚           â–²                                                     â”‚
â”‚           â”‚     â—‹ â—‹ â—‹                                          â”‚
â”‚           â”‚   â—‹   â—‹   â—‹                                        â”‚
â”‚           â”‚ â—‹       â—‹                                          â”‚
â”‚           â”‚         â•± â† Hyperplane (garis pemisah)             â”‚
â”‚           â”‚       â•±                                            â”‚
â”‚           â”‚     â•±   â— â—                                        â”‚
â”‚           â”‚   â•±   â—   â— â—                                      â”‚
â”‚           â”‚ â•±   â—       â—                                      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Feature 1                   â”‚
â”‚                                                                 â”‚
â”‚  RBF KERNEL: Untuk data yang tidak linear separable            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Original Space:         RBF Kernel Space:                â”‚   â”‚
â”‚  â”‚    â—‹ â— â—‹ â—                    â—‹ â—‹                        â”‚   â”‚
â”‚  â”‚    â— â—‹ â— â—‹    â”€â”€â”€â”€â–¶           â—‹ â—‹   (bisa dipisahkan!)   â”‚   â”‚
â”‚  â”‚    â—‹ â— â—‹ â—                  â— â— â— â—                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  KEUNGGULAN:                                                    â”‚
â”‚  âœ… Efektif di high-dimensional space                          â”‚
â”‚  âœ… Memory efficient (hanya support vectors)                   â”‚
â”‚  âŒ LAMBAT untuk dataset besar (O(nÂ²) sampai O(nÂ³))            â”‚
â”‚  âŒ WAJIB scaling                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. HYPERPARAMETER DAN ALASANNYA

### 8.1 Random Forest Hyperparameters

| Parameter | Nilai | Alasan |
|-----------|-------|--------|
| `n_estimators=100` | 100 trees | **Standard value** yang memberikan balance antara akurasi dan kecepatan. Lebih dari 100 jarang memberikan improvement signifikan. |
| `max_depth=10` (top 10) | 10 levels | **Cukup untuk 10 fitur**. Rule of thumb: max_depth â‰ˆ jumlah fitur. Mencegah overfitting. |
| `max_depth=20` (all features) | 20 levels | **Lebih dalam untuk 57 fitur** agar model bisa capture pattern yang lebih kompleks. |
| `random_state=42` | 42 | **Reproducibility** - hasil sama setiap kali dijalankan. 42 adalah "magic number" dari Hitchhiker's Guide to Galaxy. |
| `n_jobs=-1` | All cores | **Parallel processing** - memanfaatkan semua CPU cores untuk training lebih cepat. |

**Mengapa max_depth disesuaikan dengan jumlah fitur?**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MAX_DEPTH EXPLANATION                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  10 FITUR â†’ max_depth = 10                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Depth 1: Split on Feature A        â”‚                     â”‚
â”‚  â”‚ Depth 2: Split on Feature B        â”‚                     â”‚
â”‚  â”‚ ...                                 â”‚                     â”‚
â”‚  â”‚ Depth 10: Leaf node (prediction)   â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚  â†’ Setiap fitur berpeluang di-split sekali                  â”‚
â”‚                                                              â”‚
â”‚  57 FITUR â†’ max_depth = 20                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Lebih dalam untuk menangkap        â”‚                     â”‚
â”‚  â”‚ interaksi kompleks antar 57 fitur  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                              â”‚
â”‚  TRADE-OFF:                                                  â”‚
â”‚  - Terlalu dangkal â†’ Underfitting (tidak capture pattern)   â”‚
â”‚  - Terlalu dalam â†’ Overfitting (menghafal noise)            â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 8.2 XGBoost (GradientBoosting) Hyperparameters

| Parameter | Nilai | Alasan |
|-----------|-------|--------|
| `n_estimators=100` | 100 stages | **Standard boosting iterations**. Lebih banyak = lebih akurat tapi lebih lambat. |
| `max_depth=10` | 10 | **Lebih shallow dari RF** karena boosting sudah menambah kompleksitas secara iteratif. |
| `random_state=42` | 42 | Reproducibility |

**Mengapa XGBoost lebih shallow?**
```
Random Forest:      XGBoost:
Trees PARALEL       Trees SEKUENSIAL
â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”
â”‚ T1â”‚ â”‚ T2â”‚ â”‚ T3â”‚   â”‚ T1â”‚ â†’ Predict â†’ Error
â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜        â”‚
       â”‚                  â–¼
       â–¼             â”Œâ”€â”€â”€â”
    VOTING           â”‚ T2â”‚ â†’ Fokus pada Error T1
                     â””â”€â”€â”€â”˜
                          â”‚
                          â–¼
                     â”Œâ”€â”€â”€â”
                     â”‚ T3â”‚ â†’ Fokus pada Error T2
                     â””â”€â”€â”€â”˜

â†’ Kompleksitas sudah ditambah melalui boosting
â†’ Tidak perlu tree yang sangat dalam
â†’ max_depth = 10 sudah cukup
```

---

### 8.3 SVM Hyperparameters

| Parameter | Nilai | Alasan |
|-----------|-------|--------|
| `kernel='rbf'` | RBF | **Radial Basis Function** - kernel paling versatile, bisa handle non-linear patterns. |
| `C=1.0` | 1.0 | **Default regularization**. Balance antara margin besar dan misclassification rendah. |
| `gamma='scale'` | scale | **Automatic scaling** berdasarkan jumlah fitur: `1 / (n_features * X.var())` |

**Penjelasan Parameter C:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PARAMETER C EXPLAINED                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  C KECIL (0.01):                  C BESAR (100):            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ â—‹       â•± â—      â”‚             â”‚ â—‹     â•±   â—      â”‚      â”‚
â”‚  â”‚    â—‹  â•±    â—     â”‚             â”‚    â—‹â•±      â—     â”‚      â”‚
â”‚  â”‚  â—  â•±  â—‹    â—    â”‚             â”‚     â•± â—‹     â—    â”‚      â”‚
â”‚  â”‚   â•±              â”‚             â”‚   â•±              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â†’ Margin LEBAR                   â†’ Margin SEMPIT           â”‚
â”‚  â†’ Toleransi error tinggi         â†’ Toleransi error rendah  â”‚
â”‚  â†’ Simple model (underfitting?)   â†’ Complex model (overfit?)â”‚
â”‚                                                              â”‚
â”‚  C = 1.0 adalah SWEET SPOT untuk kebanyakan kasus          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Penjelasan Parameter Gamma:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PARAMETER GAMMA EXPLAINED                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  gamma = 'scale' â†’ Î³ = 1 / (n_features Ã— variance)          â”‚
â”‚                                                              â”‚
â”‚  GAMMA KECIL:                     GAMMA BESAR:              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Jangkauan LUAS   â”‚             â”‚ Jangkauan SEMPIT â”‚      â”‚
â”‚  â”‚ Pengaruh ke      â”‚             â”‚ Pengaruh hanya   â”‚      â”‚
â”‚  â”‚ banyak titik     â”‚             â”‚ titik terdekat   â”‚      â”‚
â”‚  â”‚       ~~~        â”‚             â”‚        .         â”‚      â”‚
â”‚  â”‚     ~~~~~~~      â”‚             â”‚       ...        â”‚      â”‚
â”‚  â”‚   ~~~~~~~~~~~    â”‚             â”‚        .         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â†’ Smooth boundary               â†’ Wiggly boundary          â”‚
â”‚  â†’ Underfitting risk             â†’ Overfitting risk         â”‚
â”‚                                                              â”‚
â”‚  'scale' = automatic adjustment berdasarkan data            â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. PERBANDINGAN DENGAN JURNAL PRASAD

### 9.1 Informasi Jurnal
Berdasarkan file **Prasad.pdf** yang dilampirkan, jurnal ini membahas tentang **feature selection dan machine learning untuk deteksi phishing**.

### 9.2 Perbandingan Parameter

| Aspek | Jurnal Prasad | Eksperimen Anda |
|-------|---------------|-----------------|
| **Dataset** | PhiUSIIL | PhiUSIIL (sama) |
| **Jumlah Fitur** | 63 â†’ Top features | 63 â†’ Top 10 + All 57 |
| **Feature Selection** | Multiple methods | Boruta, RFE, Correlation, ContrastFS |
| **Model** | RF, XGBoost, SVM, dll | RF, XGBoost (GB), SVM |
| **Validation** | Cross Validation | 5-Fold Stratified CV |

### 9.3 Kesamaan Pendekatan
1. **Dataset yang sama** - PhiUSIIL Phishing URL Dataset
2. **Kombinasi Feature Selection + ML** - menguji berbagai metode
3. **Multiple classifier** - membandingkan beberapa model
4. **Cross Validation** - evaluasi yang robust

### 9.4 Perbedaan dan Improvement

| Aspek | Kelebihan Eksperimen Anda |
|-------|---------------------------|
| **Transparency** | Semua hyperparameter dijelaskan dengan alasan |
| **Reproducibility** | `random_state=42` untuk hasil konsisten |
| **Stratified CV** | Menjaga proporsi kelas di setiap fold |
| **Adaptive max_depth** | Disesuaikan dengan jumlah fitur |
| **Comprehensive metrics** | Accuracy, Precision, Recall, F1, Training Time |

---

## 10. HASIL EKSPERIMEN

### 10.1 Tabel Hasil Lengkap (5-Fold Cross Validation)

#### A. ACCURACY

| Feature Set | Random Forest | XGBoost | SVM |
|-------------|---------------|---------|-----|
| **Boruta** | 0.9959 | 0.9973 | 0.9900 |
| **RFE** | 0.9976 | **0.9987** | 0.9964 |
| **Correlation** | 0.9790 | 0.9806 | 0.9777 |
| **ContrastFS** | 0.9790 | 0.9805 | 0.9777 |
| **All Features** | **0.9992** | 0.9992 | 0.9978 |

#### B. PRECISION

| Feature Set | Random Forest | XGBoost | SVM |
|-------------|---------------|---------|-----|
| **Boruta** | 0.9957 | 0.9973 | 0.9929 |
| **RFE** | 0.9968 | **0.9986** | 0.9971 |
| **Correlation** | 0.9799 | 0.9815 | 0.9788 |
| **ContrastFS** | 0.9800 | 0.9813 | 0.9788 |
| **All Features** | **0.9987** | 0.9991 | 0.9973 |

#### C. RECALL

| Feature Set | Random Forest | XGBoost | SVM |
|-------------|---------------|---------|-----|
| **Boruta** | 0.9970 | 0.9979 | 0.9896 |
| **RFE** | 0.9991 | **0.9992** | 0.9966 |
| **Correlation** | 0.9835 | 0.9846 | 0.9823 |
| **ContrastFS** | 0.9834 | 0.9847 | 0.9823 |
| **All Features** | **0.9998** | 0.9995 | 0.9989 |

#### D. F1 SCORE

| Feature Set | Random Forest | XGBoost | SVM |
|-------------|---------------|---------|-----|
| **Boruta** | 0.9964 | 0.9976 | 0.9913 |
| **RFE** | 0.9979 | **0.9989** | 0.9969 |
| **Correlation** | 0.9817 | 0.9831 | 0.9806 |
| **ContrastFS** | 0.9817 | 0.9830 | 0.9806 |
| **All Features** | **0.9993** | 0.9993 | 0.9981 |

#### E. TRAINING TIME (dalam detik)

| Feature Set | Random Forest | XGBoost | SVM |
|-------------|---------------|---------|-----|
| **Boruta** | 31.78 | 146.14 | 439.45 |
| **RFE** | 33.98 | 198.93 | 160.57 |
| **Correlation** | **18.03** | 90.99 | 1491.52 |
| **ContrastFS** | 20.31 | 94.73 | 1511.37 |
| **All Features** | 57.20 | 499.01 | 408.46 |

---

### 10.2 Visualisasi Ringkasan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AKURASI TERTINGGI                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ğŸ¥‡ All Features + RF/XGB  : 99.92%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘   â”‚
â”‚  ğŸ¥ˆ RFE + XGBoost          : 99.87%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘   â”‚
â”‚  ğŸ¥‰ RFE + Random Forest    : 99.76%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘   â”‚
â”‚                                                                          â”‚
â”‚  TOP 10 FEATURE TERBAIK: RFE + XGBoost (99.87%)                         â”‚
â”‚  - Hanya 0.05% lebih rendah dari All Features!                          â”‚
â”‚  - Dengan fitur 5x lebih sedikit (10 vs 57)                             â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRAINING TIME                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  TERCEPAT:                                                               â”‚
â”‚  ğŸ¥‡ Correlation + RF  : 18.03s  â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â”‚
â”‚  ğŸ¥ˆ ContrastFS + RF   : 20.31s  â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â”‚
â”‚  ğŸ¥‰ Boruta + RF       : 31.78s  â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â”‚
â”‚                                                                          â”‚
â”‚  TERLAMBAT:                                                              â”‚
â”‚  ğŸ¢ ContrastFS + SVM  : 1511.37s (25+ menit!)                           â”‚
â”‚  ğŸ¢ Correlation + SVM : 1491.52s (25+ menit!)                           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SPEEDUP: TOP 10 vs ALL FEATURES                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Random Forest:                                                          â”‚
â”‚    All Features: 57.20s  vs  RFE: 33.98s  â†’ 1.7x lebih cepat           â”‚
â”‚                                                                          â”‚
â”‚  XGBoost:                                                                â”‚
â”‚    All Features: 499.01s vs  RFE: 198.93s â†’ 2.5x lebih cepat           â”‚
â”‚                                                                          â”‚
â”‚  SVM:                                                                    â”‚
â”‚    All Features: 408.46s vs  RFE: 160.57s â†’ 2.5x lebih cepat           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 11. ANALISIS DAN INTERPRETASI HASIL

### 11.1 Temuan Utama

#### ğŸ”‘ Finding 1: RFE adalah Feature Selection Terbaik
```
RFE + XGBoost menghasilkan akurasi 99.87% dengan hanya 10 fitur!
- Hampir sama dengan All Features (99.92%)
- Perbedaan hanya 0.05%
- Tapi training 2.5x lebih cepat
```

**Mengapa RFE unggul?**
- RFE menggunakan **backward elimination** yang sistematis
- Mempertimbangkan **model spesifik** saat memilih fitur
- Fitur yang dipilih memiliki **predictive power** tertinggi

#### ğŸ”‘ Finding 2: Boruta vs RFE - Pendekatan Berbeda, Hasil Mirip
```
Boruta: 99.73% (XGBoost) - fokus pada fitur KONTEN (LineOfCode, NoOfJS, dll)
RFE:    99.87% (XGBoost) - fokus pada fitur TEKNIS + URL
```

Keduanya valid, tergantung use case:
- **Boruta**: Jika ingin focus pada HTML/JavaScript analysis
- **RFE**: Jika ingin kombinasi URL + konten

#### ğŸ”‘ Finding 3: Correlation & ContrastFS - Akurasi Lebih Rendah
```
Correlation/ContrastFS: ~98% - masih bagus tapi lebih rendah 2%
```

**Mengapa?**
- Keduanya memilih **fitur metadata** (HasSocialNet, HasCopyrightInfo)
- Fitur ini **lebih high-level** dan kurang granular
- Tidak menangkap pattern teknis dari kode HTML

#### ğŸ”‘ Finding 4: XGBoost Konsisten Terbaik
```
Untuk SEMUA feature set, XGBoost selalu rank 1 atau 2
- Boruta: XGBoost terbaik (99.73%)
- RFE: XGBoost terbaik (99.87%)
- Correlation: XGBoost terbaik (98.06%)
- ContrastFS: XGBoost terbaik (98.05%)
```

**Mengapa XGBoost konsisten?**
- Boosting sangat efektif untuk tabular data
- Regularization mencegah overfitting
- Handle imbalanced features dengan baik

#### ğŸ”‘ Finding 5: SVM Sangat Lambat untuk Feature Tertentu
```
SVM dengan Correlation features: 1491 detik (25 menit!)
SVM dengan ContrastFS features:  1511 detik (25 menit!)
```

**Mengapa sangat lambat?**
- Correlation/ContrastFS memilih **binary features** (0/1)
- SVM dengan RBF kernel struggle dengan data binary
- Kompleksitas O(nÂ²) to O(nÂ³) untuk 235,795 sampel

---

### 11.2 Interpretasi Fitur Terpilih

#### Mengapa Fitur Ini Penting untuk Deteksi Phishing?

**Boruta & RFE (Fitur Teknis):**

| Fitur | Interpretasi |
|-------|--------------|
| `LineOfCode` | Phishing sites biasanya sederhana (sedikit kode) |
| `NoOfJS` | Legitimate sites lebih banyak menggunakan JavaScript |
| `NoOfExternalRef` | Phishing sites sering referensi ke banyak domain eksternal |
| `NoOfCSS` | Legitimate sites lebih kompleks dalam styling |
| `LargestLineLength` | Phishing sites sering punya minified/obfuscated code |

**Correlation & ContrastFS (Fitur Metadata):**

| Fitur | Interpretasi |
|-------|--------------|
| `HasSocialNet` | Legitimate sites hampir selalu punya link sosmed |
| `HasCopyrightInfo` | Phishing sites jarang mencantumkan copyright |
| `HasDescription` | SEO legitimate sites memiliki meta description |
| `HasFavicon` | Phishing sites sering tidak punya favicon |
| `HasSubmitButton` | Phishing sites SELALU punya form submit |

---

### 11.3 Trade-off Analysis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ACCURACY vs EFFICIENCY                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Accuracy                                                                â”‚
â”‚     â–²                                                                    â”‚
â”‚ 100%â”‚         â˜… All Features                                            â”‚
â”‚     â”‚       â˜… RFE    â˜… Boruta                                           â”‚
â”‚ 99% â”‚                                                                    â”‚
â”‚     â”‚                                                                    â”‚
â”‚ 98% â”‚    â˜… Correlation/ContrastFS                                       â”‚
â”‚     â”‚                                                                    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚
â”‚           Cepat                          Lambat          Training Time   â”‚
â”‚                                                                          â”‚
â”‚  SWEET SPOT: RFE + XGBoost                                              â”‚
â”‚  - Akurasi: 99.87% (hampir maksimal)                                    â”‚
â”‚  - Training: 198.93s (2.5x lebih cepat dari All Features)               â”‚
â”‚  - Fitur: hanya 10 (mudah diinterpretasi)                               â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 12. KESIMPULAN DAN REKOMENDASI

### 12.1 Kesimpulan Utama

1. **Feature Selection BERHASIL** mengurangi fitur dari 57 menjadi 10 dengan minimal loss akurasi (0.05%)

2. **RFE adalah metode Feature Selection terbaik** untuk dataset ini dengan akurasi 99.87%

3. **XGBoost adalah model terbaik** secara konsisten di semua feature set

4. **Trade-off optimal**: RFE + XGBoost memberikan balance terbaik antara akurasi dan efisiensi

5. **SVM tidak cocok** untuk fitur binary (Correlation/ContrastFS) - sangat lambat

### 12.2 Rekomendasi untuk Deployment

| Skenario | Rekomendasi | Alasan |
|----------|-------------|--------|
| **Production (Real-time)** | RFE + Random Forest | Cepat (33.98s) dengan akurasi 99.76% |
| **Batch Processing** | RFE + XGBoost | Akurasi tertinggi (99.87%) |
| **Research/Analysis** | All Features + RF/XGB | Untuk baseline comparison |
| **Edge Device** | RFE + RF (10 fitur) | Resource terbatas, hanya butuh 10 fitur |

### 12.3 Limitasi Penelitian

1. **Dataset tunggal** - Perlu validasi di dataset lain
2. **XGBoost alternatif** - Menggunakan GradientBoosting, bukan native XGBoost
3. **Hyperparameter default** - Belum dilakukan hyperparameter tuning
4. **Tidak ada ensemble** - Belum mencoba kombinasi model

### 12.4 Saran Penelitian Lanjutan

1. **Hyperparameter Tuning** menggunakan GridSearchCV atau RandomSearchCV
2. **Ensemble Methods** - Stacking atau Voting Classifier
3. **Deep Learning** - Neural Network untuk comparison
4. **Real-time Testing** - Deploy dan test dengan URL real
5. **Adversarial Testing** - Uji ketahanan terhadap phishing yang sophisticated

---

## ğŸ“ LAMPIRAN

### A. File Output
- `TrainingTime_FIXversion/ResultFIXversion.csv` - Hasil utama
- `TrainingTime_FIXversion/complete_summary.csv` - Ringkasan lengkap
- `TrainingTime_FIXversion/selected_features_summary.csv` - Daftar fitur terpilih
- `TrainingTime_FIXversion/metrics_heatmap.png` - Visualisasi heatmap
- `TrainingTime_FIXversion/training_time_comparison.png` - Perbandingan waktu
- `TrainingTime_FIXversion/radar_chart.png` - Radar chart metrik

### B. Kode Lengkap
Lihat notebook: `Feature_Selection_Model_Training(DENGAN5-FOLD-CV).ipynb`

### C. Referensi
- PhiUSIIL Dataset
- Prasad et al. (Jurnal Feature Selection untuk Phishing Detection)
- Scikit-learn Documentation
- Boruta Documentation

---